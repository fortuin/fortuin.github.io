<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Wowchemy 5.5.0 for Hugo"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=preload as=style href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap"><link rel=stylesheet href="https://fonts.googleapis.com/css2?family=Montserrat:wght@400;700&family=Roboto+Mono&family=Roboto:wght@400;700&display=swap" media=print onload='this.media="all"'><meta name=author content="Vincent Fortuin"><meta name=description content="Vincent Fortuin's personal website."><link rel=alternate hreflang=en-us href=https://fortuin.github.io/><meta name=theme-color content="#1565c0"><link rel=stylesheet href=/css/vendor-bundle.min.c7b8d9abd591ba2253ea42747e3ac3f5.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css integrity="sha512-W0xM4mr6dEP9nREo7Z9z+9X70wytKvMGeDsj7ps2+xg5QPrEBXC8tAW1IFnzjR6eoJ90JmCnFzerQJTLzIEHjA==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/github.min.css crossorigin=anonymous title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/styles/dracula.min.css crossorigin=anonymous title=hl-dark media=print onload='this.media="all"' disabled><link rel=stylesheet href=/css/wowchemy.1052fab8b7700a3dc49ee23683097d66.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Vincent Fortuin"><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_180x180_fill_lanczos_center_3.png><link rel=canonical href=https://fortuin.github.io/><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@vincefort"><meta property="twitter:creator" content="@vincefort"><meta property="og:site_name" content="Vincent Fortuin"><meta property="og:url" content="https://fortuin.github.io/"><meta property="og:title" content="Vincent Fortuin"><meta property="og:description" content="Vincent Fortuin's personal website."><meta property="og:image" content="https://fortuin.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://fortuin.github.io/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2030-06-01T13:00:00+00:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://fortuin.github.io/?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://fortuin.github.io/"}</script><title>Vincent Fortuin</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=page-wrapper><script src=/js/wowchemy-init.min.2ed908358299dd7ab553faae685c746c.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class=page-header><header class=header--fixed><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Vincent Fortuin</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Vincent Fortuin</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li><li class=nav-item><a class=nav-link href=/#contact data-target=#contact><span>Contact</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=home-section-bg></div><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" width=270 height=270 src=/authors/vincent-fortuin/avatar_hu6b40bbbb94fd6a0b21625ee0df3f44f4_711750_270x270_fill_q75_lanczos_center.jpg alt="Vincent Fortuin"><div class=portrait-title><h2>Vincent Fortuin</h2><h3>Postdoctoral Researcher in Machine Learning</h3><h3><a href=https://www.cam.ac.uk/ target=_blank rel=noopener><span>University of Cambridge</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=/#contact aria-label=envelope><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://twitter.com/vincefort target=_blank rel=noopener aria-label=twitter><i class="fab fa-twitter big-icon"></i></a></li><li><a href="https://scholar.google.com/citations?user=XBlrYTIAAAAJ" target=_blank rel=noopener aria-label=google-scholar><i class="ai ai-google-scholar big-icon"></i></a></li><li><a href=https://www.semanticscholar.org/author/Vincent-Fortuin/41031794 target=_blank rel=noopener aria-label=semantic-scholar><i class="ai ai-semantic-scholar big-icon"></i></a></li><li><a href=https://dblp.org/pid/218/7489.html target=_blank rel=noopener aria-label=dblp><i class="ai ai-dblp big-icon"></i></a></li><li><a href=https://github.com/fortuin target=_blank rel=noopener aria-label=github><i class="fab fa-github big-icon"></i></a></li><li><a href=https://www.linkedin.com/in/vincent-fortuin-42426b134/ target=_blank rel=noopener aria-label=linkedin><i class="fab fa-linkedin big-icon"></i></a></li><li><a href=https://orcid.org/0000-0002-0640-2671 target=_blank rel=noopener aria-label=orcid><i class="ai ai-orcid big-icon"></i></a></li><li><a href=https://medium.com/@vincefort target=_blank rel=noopener aria-label=medium><i class="fab fa-medium big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>About me</h1><div class=article-style><p>I am a postdoctoral researcher at the <a href=https://www.cam.ac.uk/ target=_blank rel=noopener>University of Cambridge</a>, working in the <a href=http://mlg.eng.cam.ac.uk/ target=_blank rel=noopener>Machine Learning Group</a> with <a href=http://cbl.eng.cam.ac.uk/Public/Turner/Turner target=_blank rel=noopener>Richard Turner</a>. I am also a Research Fellow at <a href=https://www.joh.cam.ac.uk/ target=_blank rel=noopener>St. John&rsquo;s College</a> and my research is supported by a <a href=https://data.snf.ch/grants/grant/206956 target=_blank rel=noopener>Postdoc.Mobility Fellowship</a> from the <a href=https://snf.ch/en/FKhU9kAtfXx7w9AI/page/home target=_blank rel=noopener>Swiss National Science Foundation</a>.
My research focuses on the interface between deep learning and probabilistic modeling. I am particularly keen to develop models that are more interpretable and data efficient, following the Bayesian paradigm. To this end, I am mostly trying to find better priors and more efficient inference techniques for Bayesian deep learning. Apart from that, I am also interested in deep generative modeling, meta-learning, and PAC-Bayesian theory.</p><p>I did my undergraduate studies in Molecular Life Sciences at the <a href=https://www.uni-hamburg.de/en/ target=_blank rel=noopener>University of Hamburg</a>, where I worked on phylogeny inference for quickly mutating virus strains with <a href=https://www.zbh.uni-hamburg.de/en/personen/bm/atorda.html target=_blank rel=noopener>Andrew Torda</a>. I then went to <a href=https://ethz.ch/en.html target=_blank rel=noopener>ETH Zürich</a> to study Computational Biology and Bioinformatics (in a joint program with the <a href=https://www.uzh.ch/cmsssl/en.html target=_blank rel=noopener>University of Zürich</a>), with a focus on systems biology and machine learning. My master&rsquo;s studies were suported by an <a href=https://ethz.ch/students/en/studies/financial/scholarships/excellencescholarship.html target=_blank rel=noopener>ETH Excellence Scholarship</a>. My master&rsquo;s thesis was about the application of deep learning to gene regulatory network inference under supervision of <a href=https://imsb.ethz.ch/research/claassen.html target=_blank rel=noopener>Manfred Claassen</a>, for which I received the <a href=https://ethz.ch/en/the-eth-zurich/education/awards/willi-studer-prize.html target=_blank rel=noopener>Willi Studer Prize</a>. During my master&rsquo;s studies, I also spent some time in <a href=https://hannalabweb.weizmann.ac.il/ target=_blank rel=noopener>Jacob Hanna&rsquo;s group</a> at the <a href=https://www.weizmann.ac.il/pages/ target=_blank rel=noopener>Weizmann Institute of Science</a>, working on multiomics data analysis in stem cell research.
I then did my PhD in Computer Science at <a href=https://ethz.ch/en.html target=_blank rel=noopener>ETH Zürich</a> under the supervision of <a href=https://bmi.inf.ethz.ch/people/person/gunnar-raetsch/ target=_blank rel=noopener>Gunnar Rätsch</a> and <a href=https://las.inf.ethz.ch/krausea target=_blank rel=noopener>Andreas Krause</a>, where I was a member of the <a href=https://bmi.inf.ethz.ch/ target=_blank rel=noopener>Biomedical Informatics group</a> as well as the <a href=https://math.ethz.ch/sfs/eth-foundations-of-data-science.html target=_blank rel=noopener>ETH Center for the Foundations of Data Science</a>. I was supported by a <a href=https://datascience.ch/PhD-Fellows/ target=_blank rel=noopener>PhD fellowship</a> from the <a href=https://datascience.ch/ target=_blank rel=noopener>Swiss Data Science Center</a> and was also an <a href=https://ellis.eu/en/projects/priors-and-inference-for-deep-probabilistic-models target=_blank rel=noopener>ELLIS PhD student</a>.
Within my PhD studies, I visited and worked with <a href=http://www.stephanmandt.com/ target=_blank rel=noopener>Stephan Mandt</a> at the <a href=https://uci.edu/ target=_blank rel=noopener>University of California in Irvine</a> and <a href=http://cbl.eng.cam.ac.uk/Public/Turner/Turner target=_blank rel=noopener>Richard Turner</a> at the <a href=https://www.cam.ac.uk/ target=_blank rel=noopener>University of Cambridge</a>. Moreover, I completed internships at <a href=https://www.disneyresearch.com/ target=_blank rel=noopener>Disney Research Zürich</a>, working with <a href=https://studios.disneyresearch.com/people/romann-weber/ target=_blank rel=noopener>Romann Weber</a> on deep learning for natural language understanding in the <a href=https://studios.disneyresearch.com/artificial-intelligence/ target=_blank rel=noopener>Machine Intelligence and Data Science team</a>, at <a href=https://www.microsoft.com/en-us/research/lab/microsoft-research-cambridge/ target=_blank rel=noopener>Microsoft Research Cambridge</a>, working with <a href=https://www.microsoft.com/en-us/research/people/kahofman/ target=_blank rel=noopener>Katja Hofmann</a> on uncertainty quantification in deep learning in the <a href=https://www.microsoft.com/en-us/research/group/game-intelligence/ target=_blank rel=noopener>Game Intelligence team</a>, and at <a href=https://research.google/teams/brain/ target=_blank rel=noopener>Google Brain</a>, working with <a href=https://research.google/people/EffrosyniKokiopoulou/ target=_blank rel=noopener>Efi Kokiopoulou</a> and <a href=https://rodolphejenatton.com/ target=_blank rel=noopener>Rodolphe Jenatton</a> on uncertainty estimation and out-of-distribution detection in the Reliable Deep Learning team. My <a href=https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Bacon_number target=_blank rel=noopener>Erdös–Bacon number</a> is 6.</p></div><div class=row><div class=col-md-5><div class=section-subheading>Interests</div><ul class="ul-interests mb-0"><li>Bayesian deep learning</li><li>Deep generative modeling</li><li>Meta-learning</li><li>PAC-Bayesian theory</li></ul></div><div class=col-md-7><div class=section-subheading>Education</div><ul class="ul-edu fa-ul mb-0"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>PhD in Machine Learning, 2021</p><p class=institution>ETH Zürich</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MSc in Computational Biology and Bioinformatics, 2017</p><p class=institution>ETH Zürich</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BSc in Molecular Life Sciences, 2015</p><p class=institution>University of Hamburg</p></div></li></ul></div></div></div></div></div></section><section id=featured class="home-section wg-featured"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Selected Publications</h1></div><div class="col-12 col-lg-8"><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Vincent Fortuin</span>, <span>Adrià Garriga-Alonso</span>, <span>Florian Wenzel</span>, <span>Gunnar Rätsch</span>, <span>Richard E Turner</span>, <span>Mark van der Wilk</span>, <span>Laurence Aitchison</span></div><span class=article-date>January, 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In ICLR</span></div><a href=/publication/fortuin2022bayesian/><div class=img-hover-zoom><img src=/publication/fortuin2022bayesian/featured_hufac59d8b8053fe1bd1e51ce3910649d3_460771_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="Bayesian Neural Network Priors Revisited" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/fortuin2022bayesian/>Bayesian Neural Network Priors Revisited</a></div><a href=/publication/fortuin2022bayesian/ class=summary-link><div class=article-style><p>We show that empirical weight distributions of SGD-trained neural networks are heavy-tailed and correlated and that incorporating these insights into Bayesian neural network priors can improve their performance and reduce the cold-posterior effect.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2102.06571 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/bnn_priors target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Vincent Fortuin</span></div><span class=article-date>January, 2022</span>
<span class=middot-divider></span>
<span class=pub-publication>In International Statistical Review</span></div><a href=/publication/fortuin2022priors/><div class=img-hover-zoom><img src=/publication/fortuin2022priors/featured_huaa756de986e4ce82f5c3a32df913b0fa_215699_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="Priors in Bayesian Deep Learning: A Review" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/fortuin2022priors/>Priors in Bayesian Deep Learning: A Review</a></div><a href=/publication/fortuin2022priors/ class=summary-link><div class=article-style><p>We provide a comprehensive review of the recent advances regarding the choice of priors for Bayesian neural networks, variational autoencoders, and (deep) Gaussian processes.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2105.06868 target=_blank rel=noopener>PDF</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span>Jonas Rothfuss</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Martin Josifoski</span>, <span>Andreas Krause</span></div><span class=article-date>January, 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>In ICML</span></div><a href=/publication/rothfuss2021pacoh/><div class=img-hover-zoom><img src=/publication/rothfuss2021pacoh/featured_hu7ab226ed7d16c6feb6e5c4aa748a80c5_395164_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/rothfuss2021pacoh/>PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees</a></div><a href=/publication/rothfuss2021pacoh/ class=summary-link><div class=article-style><p>We derive a novel PAC-Bayes bound for meta-learning with Bayesian models, which gives rise to a computationally efficient meta-learning method that outperforms existing approaches on a range of tasks, especially when the number of meta-tasks is small.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2002.05551 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/jonasrothfuss/meta_learning_pacoh target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span>Francesco D'Angelo</span>, <span class=author-highlighted>Vincent Fortuin</span></div><span class=article-date>January, 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>In NeurIPS (spotlight)</span></div><a href=/publication/dangelo2021repulsive/><div class=img-hover-zoom><img src=/publication/dangelo2021repulsive/featured_hu1c3e716a1edde60516c03a3c63d6349b_622065_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="Repulsive Deep Ensembles are Bayesian" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/dangelo2021repulsive/>Repulsive Deep Ensembles are Bayesian</a></div><a href=/publication/dangelo2021repulsive/ class=summary-link><div class=article-style><p>We show that introducing a repulsive force between the members of a deep ensemble can improve the ensemble&rsquo;s diversity and performance, especially when this force is applied in the function space, and that it can also guarantee asymptotic convergence to the true Bayes posterior.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2106.11642 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/repulsive_ensembles target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span>Alexander Immer</span>, <span>Matthias Bauer</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Gunnar Rätsch</span>, <span>Mohammad Emtiyaz Khan</span></div><span class=article-date>January, 2021</span>
<span class=middot-divider></span>
<span class=pub-publication>In ICML</span></div><a href=/publication/immer2021scalable/><div class=img-hover-zoom><img src=/publication/immer2021scalable/featured_hubaeaa3fff8476f0a6fc13d7c718b6657_270923_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/immer2021scalable/>Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning</a></div><a href=/publication/immer2021scalable/ class=summary-link><div class=article-style><p>We show that a Laplace-Generalized-Gauss-Newton approximation to the marginal likelihood of Bayesian neural networks can effectively be used for model selection and can often discover better hyperparameter settings than cross-validation.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2104.04975 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AlexImmer/Laplace target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Vincent Fortuin</span>, <span>Dmitry Baranchuk</span>, <span>Gunnar Rätsch</span>, <span>Stephan Mandt</span></div><span class=article-date>January, 2020</span>
<span class=middot-divider></span>
<span class=pub-publication>In AISTATS</span></div><a href=/publication/fortuin2020gp-vae/><div class=img-hover-zoom><img src=/publication/fortuin2020gp-vae/featured_hu036362cfa5a689b0eabdcf9addd1de2f_455497_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="GP-VAE: Deep Probabilistic Time Series Imputation" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/fortuin2020gp-vae/>GP-VAE: Deep Probabilistic Time Series Imputation</a></div><a href=/publication/fortuin2020gp-vae/ class=summary-link><div class=article-style><p>We show that using a Gaussian process prior in the latent space of a variational autoencoder can improve time series imputation performance, while still allowing for computationally efficient inference through a variational Gauss-Markov process.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1907.04155 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/GP-VAE target=_blank rel=noopener>Code</a></div></div><div class="card-simple view-card"><div class=article-metadata><div><span class=author-highlighted>Vincent Fortuin</span>, <span>Matthias Hüser</span>, <span>Francesco Locatello</span>, <span>Heiko Strathmann</span>, <span>Gunnar Rätsch</span></div><span class=article-date>January, 2019</span>
<span class=middot-divider></span>
<span class=pub-publication>In ICLR</span></div><a href=/publication/fortuin2019som-vae/><div class=img-hover-zoom><img src=/publication/fortuin2019som-vae/featured_hudb0c82f6e5da411b2c6f5cb12b415ab6_195076_808x455_fill_q75_h2_lanczos_smart1_3.webp height=455 width=808 class=article-banner alt="SOM-VAE: Interpretable Discrete Representation Learning on Time Series" loading=lazy></div></a><div class="section-subheading article-title mb-1 mt-3"><a href=/publication/fortuin2019som-vae/>SOM-VAE: Interpretable Discrete Representation Learning on Time Series</a></div><a href=/publication/fortuin2019som-vae/ class=summary-link><div class=article-style><p>We propose a novel version of the classical self-organizing map, which can be used as a structural prior in the latent space of a variational autoencoder, enabling interpretable representations of time series.</p></div></a><div class=btn-links><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1806.02199 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/SOM-VAE target=_blank rel=noopener>Code</a></div></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>All Publications</h1></div><div class="col-12 col-lg-8"><div class="alert alert-note"><div>Quickly discover relevant content by <a href=./publication/>filtering publications</a>.</div></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Adrià Garriga-Alonso</span>, <span>Florian Wenzel</span>, <span>Gunnar Rätsch</span>, <span>Richard E Turner</span>, <span>Mark van der Wilk</span>, <span>Laurence Aitchison</span></span>
(2022).
<a href=/publication/fortuin2022bayesian/>Bayesian Neural Network Priors Revisited</a>.
In ICLR.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2102.06571 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/bnn_priors target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Mark Collier</span>, <span>Florian Wenzel</span>, <span>James Allingham</span>, <span>Jeremiah Liu</span>, <span>Dustin Tran</span>, <span>Balaji Lakshminarayanan</span>, <span>Jesse Berent</span>, <span>Rodolphe Jenatton</span>, <span>Effrosyni Kokiopoulou</span></span>
(2022).
<a href=/publication/fortuin2022deep/>Deep Classifiers with Label Noise Modeling and Distance Awareness</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.02609 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/google/edward2/blob/main/edward2/tensorflow/layers/hetsngp.py target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Lauro Langosco di Langosco</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Heiko Strathmann</span></span>
(2022).
<a href=/publication/langosco2022neural/>Neural Variational Gradient Descent</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2107.10731 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Simon Bing</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Gunnar Rätsch</span></span>
(2022).
<a href=/publication/bing2021on/>On Disentanglement in Gaussian Process Variational Autoencoders</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2102.05507 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/dgp-vae target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Tristan Cinquin</span>, <span>Alexander Immer</span>, <span>Max Horn</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2022).
<a href=/publication/cinquin2022pathologies/>Pathologies in priors and inference for Bayesian transformers</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.04020 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span></span>
(2022).
<a href=/publication/fortuin2022priors/>Priors in Bayesian Deep Learning: A Review</a>.
In International Statistical Review.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2105.06868 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Alexander Immer</span>, <span>Lucas Torroba Hennigen</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Ryan Cotterell</span></span>
(2022).
<a href=/publication/immer2022probing/>Probing as Quantifying the Inductive Bias of Pre-trained Representations</a>.
In ACL.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.08388 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Noah Berner</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Jonas Landman</span></span>
(2022).
<a href=/publication/berner2022quantum/>Quantum Bayesian Neural Networks</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2107.09599 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/NoahBerner/quantum_bayesian_neural_networks target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/fortuin2021choice/>On the Choice of Priors in Bayesian Deep Learning</a>.
PhD thesis.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.research-collection.ethz.ch/handle/20.500.11850/523269 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Laura Manduchi</span>, <span>Matthias Hüser</span>, <span>Martin Faltys</span>, <span>Julia Vogt</span>, <span>Gunnar Rätsch</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/manduchi2021t-dpsom/>T-DPSOM: An Interpretable Clustering Method for Unsupervised Learning of Patient Health States</a>.
In ACM CHIL.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://dl.acm.org/doi/10.1145/3450439.3451872 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Francesco D'Angelo</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/dangelo2021annealed/>Annealed Stein Variational Gradient Descent</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2101.09815 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Adrià Garriga-Alonso</span>, <span>Mark van der Wilk</span>, <span>Laurence Aitchison</span></span>
(2021).
<a href=/publication/fortuin2021bnnpriors/>BNNpriors: A library for Bayesian neural network inference with different prior distributions</a>.
In Software Impacts.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.sciencedirect.com/science/article/pii/S2665963821000270 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/bnn_priors target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Seth Nabarro</span>, <span>Stoil Ganev</span>, <span>Adrià Garriga-Alonso</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Mark van der Wilk</span>, <span>Laurence Aitchison</span></span>
(2021).
<a href=/publication/nabarro2021data/>Data augmentation in Bayesian neural networks and the cold posterior effect</a>.
In arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2106.05586 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Adrià Garriga-Alonso</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/garriga-alonso2021exact/>Exact Langevin Dynamics with Stochastic Gradients</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2102.01691 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Metod Jazbec</span>, <span>Michael Pearce</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/jazbec2021factorized/>Factorized Gaussian Process Variational Autoencoders</a>.
In AABI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2011.07255 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/metodj/FGP-VAE target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Margherita Rosnati</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/rosnati2021mgp-atttcn/>MGP-AttTCN: An Interpretable Machine Learning Model for the Prediction of Sepsis</a>.
In PLOS ONE.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1909.12637 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/mmr12/MGP-AttTCN target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Andreas Kopf</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Vignesh Ram Somnath</span>, <span>Manfred Claassen</span></span>
(2021).
<a href=/publication/kopf2021mixture-of-experts/>Mixture-of-Experts Variational Autoencoder for clustering and generating from similarity-based representations</a>.
In PLOS Computational Biology.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1910.07763 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Nikolaos Mourdoukoutas</span>, <span>Marco Federici</span>, <span>Georges Pantalos</span>, <span>Mark van der Wilk</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/mourdoukoutas2021a/>A Bayesian Approach to Invariant Deep Neural Networks</a>.
In ICML workshop on Uncertainty and Robustness in Deep Learning.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2107.09301 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Jonas Rothfuss</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Martin Josifoski</span>, <span>Andreas Krause</span></span>
(2021).
<a href=/publication/rothfuss2021pacoh/>PACOH: Bayes-Optimal Meta-Learning with PAC-Guarantees</a>.
In ICML.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2002.05551 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/jonasrothfuss/meta_learning_pacoh target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Francesco D'Angelo</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2021).
<a href=/publication/dangelo2021repulsive/>Repulsive Deep Ensembles are Bayesian</a>.
In NeurIPS (spotlight).<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2106.11642 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/repulsive_ensembles target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Metod Jazbec</span>, <span>Matthew Ashman</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Michael Pearce</span>, <span>Stephan Mandt</span>, <span>Gunnar Rätsch</span></span>
(2021).
<a href=/publication/jazbec2021scalable/>Scalable Gaussian Process Variational Autoencoders</a>.
In AISTATS.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2010.13472 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/SVGP-VAE target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Gideon Dresdner</span>, <span>Heiko Strathmann</span>, <span>Gunnar Rätsch</span></span>
(2021).
<a href=/publication/fortuin2021scalable/>Scalable Gaussian Processes on Discrete Domains</a>.
In IEEE Access.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1810.10368 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Alexander Immer</span>, <span>Matthias Bauer</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Gunnar Rätsch</span>, <span>Mohammad Emtiyaz Khan</span></span>
(2021).
<a href=/publication/immer2021scalable/>Scalable Marginal Likelihood Estimation for Model Selection in Deep Learning</a>.
In ICML.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2104.04975 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/AlexImmer/Laplace target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>James Allingham</span>, <span>Florian Wenzel</span>, <span>Zelda Mariet</span>, <span>Basil Mustafa</span>, <span>Joan Puigcerver</span>, <span>Neil Houlsby</span>, <span>Ghassen Jerfel</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Balaji Lakshminarayanan</span>, <span>Jasper Snoek</span>, <span>Dustin Tran</span>, <span>Carlos Riquelme Ruiz</span>, <span>Rodolphe Jenatton</span></span>
(2021).
<a href=/publication/allingham2021sparse/>Sparse MoEs meet Efficient Ensembles</a>.
In arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2110.03360 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Francesco D'Angelo</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Florian Wenzel</span></span>
(2021).
<a href=/publication/dangelo2021on/>On Stein Variational Neural Network Ensembles</a>.
In arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2106.10760 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Kamil Ciosek</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Ryota Tomioka</span>, <span>Katja Hofmann</span>, <span>Richard E Turner</span></span>
(2020).
<a href=/publication/ciosek2020conservative/>Conservative Uncertainty Estimation By Fitting Prior Networks</a>.
In ICLR.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href="https://openreview.net/forum?id=BJlahxHYDS" target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/microsoft/conservative-uncertainty-estimation-random-priors target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Dmitry Baranchuk</span>, <span>Gunnar Rätsch</span>, <span>Stephan Mandt</span></span>
(2020).
<a href=/publication/fortuin2020gp-vae/>GP-VAE: Deep Probabilistic Time Series Imputation</a>.
In AISTATS.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1907.04155 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/GP-VAE target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Matthew Ashman</span>, <span>Jonathan So</span>, <span>Will Tebbutt</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Michael Pearce</span>, <span>Richard E Turner</span></span>
(2020).
<a href=/publication/ashman2020sparse/>Sparse Gaussian Process Variational Autoencoders</a>.
In arXiv.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/2010.10177 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/MattAshman/sgpvae target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Laura Manduchi</span>, <span>Matthias Hüser</span>, <span>Gunnar Rätsch</span>, <span class=author-highlighted>Vincent Fortuin</span></span>
(2019).
<a href=/publication/manduchi2019dpsom/>DPSOM: Deep Probabilistic Clustering with Self-Organizing Maps</a>.
In NeurIPS workshop on Machine Learning for Health.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1910.01590 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/dpsom target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Heiko Strathmann</span>, <span>Gunnar Rätsch</span></span>
(2019).
<a href=/publication/fortuin2019meta-learning/>Meta-Learning Mean Functions for Gaussian Processes</a>.
In NeurIPS workshop on Bayesian Deep Learning.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1901.08098 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Andreas Georgiou</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Harun Mustafa</span>, <span>Gunnar Rätsch</span></span>
(2019).
<a href=/publication/georgiou2019meta2/>META^2: Memory-efficient taxonomic classification and abundance estimation for metagenomics with deep learning</a>.
In MLCB.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1909.13146 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ag14774/META2 target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Matthias Hüser</span>, <span>Francesco Locatello</span>, <span>Heiko Strathmann</span>, <span>Gunnar Rätsch</span></span>
(2019).
<a href=/publication/fortuin2019som-vae/>SOM-VAE: Interpretable Discrete Representation Learning on Time Series</a>.
In ICLR.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://arxiv.org/abs/1806.02199 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary btn-page-header btn-sm" href=https://github.com/ratschlab/SOM-VAE target=_blank rel=noopener>Code</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span class=author-highlighted>Vincent Fortuin</span>, <span>Romann M Weber</span>, <span>Sasha Schriber</span>, <span>Diana Wotruba</span>, <span>Markus H Gross</span></span>
(2018).
<a href=/publication/fortuin2018inspireme/>InspireMe: Learning Sequence Models for Stories</a>.
In AAAI.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewPaper/16100 target=_blank rel=noopener>PDF</a></p></div><div class="pub-list-item view-citation" style=margin-bottom:1rem><i class="far fa-file-alt pub-icon" aria-hidden=true></i>
<span class="article-metadata li-cite-author"><span>Tim GJ Rudner</span>, <span class=author-highlighted>Vincent Fortuin</span>, <span>Yee Whye Teh</span>, <span>Yarin Gal</span></span>
(2018).
<a href=/publication/rudner2018on/>On the Connection between Neural Processes and Gaussian Processes with Deep Kernels</a>.
In NeurIPS workshop on Bayesian Deep Learning.<p><a class="btn btn-outline-primary btn-page-header btn-sm" href=http://bayesiandeeplearning.org/2018/papers/128.pdf target=_blank rel=noopener>PDF</a></p></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class=row><div class="section-heading col-12 col-lg-4 mb-3 mb-lg-0 d-flex flex-column align-items-center align-items-lg-start"><h1 class=mb-0>Contact</h1></div><script src=https://www.google.com/recaptcha/api.js async defer></script><div class="col-12 col-lg-8"><div class=mb-3><form name=contact method=post action=https://formspree.io/f/xpzbynnk data-netlify-recaptcha=true><div class="form-group form-inline"><label class=sr-only for=inputName>Name</label>
<input type=text name=name class="form-control w-100" id=inputName placeholder=Name required></div><div class="form-group form-inline"><label class=sr-only for=inputEmail>Email</label>
<input type=email name=email class="form-control w-100" id=inputEmail placeholder=Email required></div><div class=form-group><label class=sr-only for=inputMessage>Message</label>
<textarea name=message class=form-control id=inputMessage rows=5 placeholder=Message required></textarea></div><div class=d-none><label>Do not fill this field unless you are a bot: <input name=_gotcha></label></div><div class=g-recaptcha data-sitekey=6LcPQIYfAAAAAIDajAIstWYTxehdvwKKxBF9s4eH></div></br><button type=submit class="btn btn-primary px-3 py-2 w-100">Send</button></form></div><ul class=fa-ul><li><i class="fa-li fas fa-envelope fa-2x" aria-hidden=true></i>
<span id=person-email><a href=mailto:vbf21@cam.ac.uk>vbf21@cam.ac.uk</a></span></li></ul></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2022 Vincent Fortuin. This work is licensed under <a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank>CC BY NC ND 4.0</a></p><p class="powered-by footer-license-icons"><a href=https://creativecommons.org/licenses/by-nc-nd/4.0 rel="noopener noreferrer" target=_blank aria-label="Creative Commons"><i class="fab fa-creative-commons fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-by fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nc fa-2x" aria-hidden=true></i>
<i class="fab fa-creative-commons-nd fa-2x" aria-hidden=true></i></a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.fab8b449b814cc9f95b22fcf2e45f05b.js></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/highlight.min.js integrity="sha512-Ypjm0o7jOxAd4hpdoppSEN0TQOC19UtPAqD+4s5AlXmUvbmmS/YMxYqAqarQYyxTnB6/rqip9qcxlNB/3U9Wdg==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/r.min.js crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@10.2.1/build/languages/latex.min.js crossorigin=anonymous></script>
<script id=search-hit-fuse-template type=text/x-template>
        <div class="search-hit" id="summary-{{key}}">
          <div class="search-hit-content">
            <div class="search-hit-name">
              <a href="{{relpermalink}}">{{title}}</a>
              <div class="article-metadata search-hit-type">{{type}}</div>
              <p class="search-hit-description">{{snippet}}</p>
            </div>
          </div>
        </div>
      </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script>
<script id=page-data type=application/json>{"use_headroom":false}</script><script src=/en/js/wowchemy.min.ab2f2890dbe3e2e83579366d3d6e8fd9.js></script><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div><script src=/js/wowchemy-publication.68f8d7090562ca65fc6d3cb3f8f2d2cb.js type=module></script></body></html>